{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PROBLEM B5\n",
    "\n",
    "Build and train a neural network model using the Daily Max Temperature.csv dataset.\n",
    "Use MAE as the metrics of your neural network model.\n",
    "We provided code for normalizing the data. Please do not change the code.\n",
    "Do not use lambda layers in your model.\n",
    "The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n",
    "\n",
    "Desired MAE < 0.2 on the normalized dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-max-temperatures.csv'\n",
    "urllib.request.urlretrieve(data_url, 'daily-max-temperatures.csv')\n",
    "\n",
    "time_step = []\n",
    "temps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('daily-max-temperatures.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    step = 0\n",
    "    for row in reader:\n",
    "        # YOUR CODE HERE\n",
    "        temps.append(float(row[1]))\n",
    "        # YOUR CODE HERE\n",
    "        time_step.append(step)\n",
    "        step=step + 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "series= np.array(temps)\n",
    "\n",
    "# Normalization Function. DO NOT CHANGE THIS CODE\n",
    "min=np.min(series)\n",
    "max=np.max(series)\n",
    "series -= min\n",
    "series /= max\n",
    "time=np.array(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "split_time=2500\n",
    "\n",
    "# YOUR CODE HERE\n",
    "time_train= time[:split_time]\n",
    "x_train=series[:split_time]\n",
    "time_valid=time[split_time:]\n",
    "x_valid=series[split_time:]\n",
    "\n",
    "# DO NOT CHANGE THIS CODE\n",
    "window_size=64\n",
    "batch_size=256\n",
    "shuffle_buffer_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "train_set=windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "print(train_set)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    # YOUR CODE HERE.\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, \n",
    "                           strides = 1, padding='causal',\n",
    "                           activation='relu',\n",
    "                           input_shape=[None, 1]),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer='adam', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 7s 54ms/step - loss: 0.0300 - mae: 0.2012\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0099 - mae: 0.1014\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0072 - mae: 0.0932\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 0.0067 - mae: 0.0913\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0062 - mae: 0.0845\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0058 - mae: 0.0826\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0056 - mae: 0.0814\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0055 - mae: 0.0808\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0055 - mae: 0.0806\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0055 - mae: 0.0803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f5cc0f6a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_B5.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
