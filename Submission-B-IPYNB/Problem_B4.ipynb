{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM B4\n",
    "Build and train a classifier for the BBC-text dataset.\n",
    "\n",
    "This is a multiclass classification problem.\n",
    "\n",
    "Do not use lambda layers in your model.\n",
    "\n",
    "The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
    "\n",
    "Desired accuracy and validation_accuracy > 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv\n",
    "import urllib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bbc-text.csv', <http.client.HTTPMessage at 0x27d6c1b68f0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc = ('https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
    "urllib.request.urlretrieve(bbc, 'bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "# Make sure you used all of these parameters or you can not pass this test\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Using \"shuffle=False\"\n",
    "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\",\n",
    "                \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\",\n",
    "                \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\",\n",
    "                \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\n",
    "                \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\",\n",
    "                \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \n",
    "                \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \n",
    "                \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "sentences = []\n",
    "labels =[]\n",
    "\n",
    "with open('bbc-text.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        sentence = row[1]\n",
    "        for word in stopwords:\n",
    "            token = \" \" + word + \" \"\n",
    "            sentence = sentence.replace(token, \" \")\n",
    "        sentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(sentences) * training_portion)\n",
    "\n",
    "train_sentences = sentences[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "\n",
    "validation_sentences = sentences[train_size:]\n",
    "validation_labels = labels[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your tokenizer with training data\n",
    "# You can also use Tokenizer to encode your label.\n",
    "# YOUR CODE HERE\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
    "validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "\n",
    "train_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # YOUR CODE HERE.\n",
    "    # YOUR CODE HERE. DO not change the last layer or test may fail\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 2s 12ms/step - loss: 1.7650 - accuracy: 0.2281 - val_loss: 1.7320 - val_accuracy: 0.2270\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.6864 - accuracy: 0.2303 - val_loss: 1.6415 - val_accuracy: 0.2292\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.5753 - accuracy: 0.2702 - val_loss: 1.5215 - val_accuracy: 0.3685\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4269 - accuracy: 0.4888 - val_loss: 1.3616 - val_accuracy: 0.5461\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.2396 - accuracy: 0.6135 - val_loss: 1.1726 - val_accuracy: 0.6247\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0432 - accuracy: 0.7348 - val_loss: 0.9957 - val_accuracy: 0.7910\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.8653 - accuracy: 0.8489 - val_loss: 0.8392 - val_accuracy: 0.8360\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.7121 - accuracy: 0.8989 - val_loss: 0.7111 - val_accuracy: 0.8607\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.5838 - accuracy: 0.9152 - val_loss: 0.5980 - val_accuracy: 0.8899\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.9315 - val_loss: 0.5118 - val_accuracy: 0.8966\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.9433 - val_loss: 0.4488 - val_accuracy: 0.8989\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.9466 - val_loss: 0.3936 - val_accuracy: 0.9124\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.2834 - accuracy: 0.9551 - val_loss: 0.3548 - val_accuracy: 0.9124\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.9612 - val_loss: 0.3177 - val_accuracy: 0.9191\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.2067 - accuracy: 0.9657 - val_loss: 0.2923 - val_accuracy: 0.9213\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1797 - accuracy: 0.9674 - val_loss: 0.2734 - val_accuracy: 0.9213\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.1580 - accuracy: 0.9742 - val_loss: 0.2581 - val_accuracy: 0.9258\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.9781 - val_loss: 0.2430 - val_accuracy: 0.9258\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1239 - accuracy: 0.9826 - val_loss: 0.2317 - val_accuracy: 0.9258\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.1105 - accuracy: 0.9860 - val_loss: 0.2247 - val_accuracy: 0.9281\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0981 - accuracy: 0.9882 - val_loss: 0.2156 - val_accuracy: 0.9303\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0882 - accuracy: 0.9888 - val_loss: 0.2131 - val_accuracy: 0.9303\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.9927 - val_loss: 0.2043 - val_accuracy: 0.9326\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0717 - accuracy: 0.9944 - val_loss: 0.1999 - val_accuracy: 0.9303\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0647 - accuracy: 0.9949 - val_loss: 0.1980 - val_accuracy: 0.9326\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0584 - accuracy: 0.9966 - val_loss: 0.1920 - val_accuracy: 0.9348\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0530 - accuracy: 0.9966 - val_loss: 0.1907 - val_accuracy: 0.9371\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0482 - accuracy: 0.9983 - val_loss: 0.1892 - val_accuracy: 0.9348\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0438 - accuracy: 0.9989 - val_loss: 0.1860 - val_accuracy: 0.9371\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0401 - accuracy: 0.9989 - val_loss: 0.1854 - val_accuracy: 0.9393\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9989 - val_loss: 0.1822 - val_accuracy: 0.9371\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9989 - val_loss: 0.1829 - val_accuracy: 0.9371\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9989 - val_loss: 0.1814 - val_accuracy: 0.9371\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9989 - val_loss: 0.1786 - val_accuracy: 0.9348\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9989 - val_loss: 0.1777 - val_accuracy: 0.9393\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9989 - val_loss: 0.1778 - val_accuracy: 0.9371\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9989 - val_loss: 0.1774 - val_accuracy: 0.9393\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9348\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9371\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9416\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9371\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9393\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9393\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9393\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9438\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9393\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9416\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9393\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9393\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27d6c8d5780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, train_label_seq,\n",
    "          epochs=50,\n",
    "          validation_data = (validation_padded, validation_label_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_B4.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
