{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================\n",
    "PROBLEM B3\n",
    "Build a CNN based classifier for Rock-Paper-Scissors dataset.\n",
    "Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
    "This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
    "Don't use lambda layers in your model.\n",
    "The dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n",
    "Desired accuracy AND validation_accuracy > 83% \n",
    "========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://github.com/dicodingacademy/assets/releases/download/release-rps/rps.zip'\n",
    "urllib.request.urlretrieve(data_url, 'rps.zip')\n",
    "local_file = 'rps.zip'\n",
    "zip_ref = zipfile.ZipFile(local_file, 'r')\n",
    "zip_ref.extractall('data/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1764 images belonging to 3 classes.\n",
      "Found 756 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"data/rps\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255.,\n",
    "    rotation_range= 40,\n",
    "    width_shift_range= 0.2,\n",
    "    height_shift_range= 0.2,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True,\n",
    "    fill_mode= 'nearest',\n",
    "    validation_split=0.3\n",
    ")\n",
    "# YOUR IMAGE SIZE SHOULD BE 150x150\n",
    "# Make sure you used \"categorical\"\n",
    "# YOUR CODE HERE\n",
    "train_generator= train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                   batch_size=16,\n",
    "                                                   subset='training',\n",
    "                                                   color_mode='rgb',\n",
    "                                                   class_mode='categorical',\n",
    "                                                   target_size=(150, 150))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale= 1. /255.,\n",
    "    validation_split=0.3\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                              batch_size=16,\n",
    "                                                              subset='validation',\n",
    "                                                              color_mode='rgb',\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('val_accuracy') > 0.91):\n",
    "            print(\"\\nVal Accuracy > 91%\")\n",
    "            print(\"\\nTraining Selesai\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 6s 225ms/step - loss: 1.9036 - accuracy: 0.3281 - val_loss: 1.1049 - val_accuracy: 0.3298\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 1.3667 - accuracy: 0.3125 - val_loss: 1.0967 - val_accuracy: 0.3338\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 1.1136 - accuracy: 0.4156 - val_loss: 1.0904 - val_accuracy: 0.3311\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 1.1067 - accuracy: 0.3625 - val_loss: 1.1106 - val_accuracy: 0.3338\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 1.1371 - accuracy: 0.4906 - val_loss: 1.2125 - val_accuracy: 0.3418\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 1.0234 - accuracy: 0.5406 - val_loss: 0.7258 - val_accuracy: 0.5891\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 1.0803 - accuracy: 0.5750 - val_loss: 0.7530 - val_accuracy: 0.5838\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.9044 - accuracy: 0.5779 - val_loss: 1.3120 - val_accuracy: 0.3617\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 4s 220ms/step - loss: 0.8701 - accuracy: 0.6234 - val_loss: 0.6891 - val_accuracy: 0.5957\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.7141 - accuracy: 0.6625 - val_loss: 0.5040 - val_accuracy: 0.7939\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 4s 215ms/step - loss: 0.7114 - accuracy: 0.7219 - val_loss: 0.6289 - val_accuracy: 0.6184\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.6441 - accuracy: 0.7406 - val_loss: 0.3768 - val_accuracy: 0.8989\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.5829 - accuracy: 0.7312 - val_loss: 0.6033 - val_accuracy: 0.6330\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 4s 214ms/step - loss: 0.5160 - accuracy: 0.7875 - val_loss: 0.5725 - val_accuracy: 0.7513\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.5238 - accuracy: 0.7906 - val_loss: 0.5054 - val_accuracy: 0.7274\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8531\n",
      "Val Accuracy > 91%\n",
      "\n",
      "Training Selesai\n",
      "20/20 [==============================] - 4s 226ms/step - loss: 0.4324 - accuracy: 0.8531 - val_loss: 0.1664 - val_accuracy: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d0cf099c60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = Custom_callback()\n",
    "\n",
    "validation_steps = validation_generator.samples / validation_generator.batch_size - 1\n",
    "\n",
    "model.fit(train_generator, \n",
    "          validation_data = validation_generator,\n",
    "          epochs=20,\n",
    "          steps_per_epoch= 20,\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks=callbacks\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_B3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
